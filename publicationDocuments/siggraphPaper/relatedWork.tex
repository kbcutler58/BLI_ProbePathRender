\section{Related Work}

\subsection{Mouse Sensor Tracking}

With a typical mouse sensor, $x$ and $y$ displacements are outputted by comparing the images taken by the low-resolution camera at the bottom of the sensor. It thus works quite well a computer mouse since it just needs to lie on a rough surface. With a computer mouse, every movement updates the mouse position for the user and the user only cares about the position in the virtual desktop. There is no consideration for where the mouse is located on the surface and indeed mouse sensors were never designed with that in mind.\\
\\
For our purposes, we want to measure displacement on a 2D surface but we care quite a bit about its exact location on that surface. If the user only moves the mouse horizontally or vertically then we could obtain an accurate location on the real surface easily. However, the probe is bound to be rotated on the surface and when that happens, the axis by which the mouse sensor reads $x$ and $y$ displacement also changes.\\
\\
To overcome the problem of not knowing the orientation of the $x$ and $y$ directions, we could attach a compass to the hardware. That combined system would work well if we were measuring on flat surfaces. However, we are aiming to measure on curved surfaces, thus when the orientation changes, it might be in a direction that a compass could not detect. We thus add an accelerometer and gyroscope to the system in order to get a complete picture of the orientation. 


\subsection{3D Tracking}

Even though we are tracking on a surface we would still need a tracking system that gives us the 3D location of an object. This is due to the fact that our surfaces are arbitrary. 

For our purposes, we needed a tracking system that gave us a 3D location. This is due to the fact that we want to track on a surface but won't know the shape of the surface in advance. Because we do not know its shape in advance, we cannot make assumptions about tracking on it the way we would a 2D plane. Instead we need to acquire 3D coordinates and reconcile them with the surface. \\
\\
Motion capture in the entertainment industry would give us 3D location. Additionally, using a Kinect with a depth map would also give us 3D location. We could have also tried using multiple images to get the sense of depth and acquire a 3D location using that method. All of these ideas however require the object to always be in view of the camera. For the purposes of a clinical setting, that is not practical and we thus needed to explore alternatives. \\
\\
There is currently considerable research on Electromagnetic Tracking for clinical applications \ref{emTrackingReview}. This would give a 3D location for a medical device probe. The systems currently in development do provide millimeter-level precision. These systems have proven to be expensive and difficult to implement. Once our system has been perfected, it would be inexpensive and simple to operate. Additionally, our system guarantees that we are tracking on the surface of a patient which is the main goal of this project. 

\subsection{3D Ultrasound}

There are 3D ultrasound systems **INSERT REFERENCE** which do track on the surface of a patient. It takes ultrasound readings and uses orientation and displacement sensors to help align the readings in order to generate a 3D data set of the inside of the patient. Using this system, orientation and displacement information is combined to generate complete paths. The paper did not consider the exact location on the surface where they placed the probe. They just used the path information to help stitch together the data set. \\
\\
Our technology is meant to use this path information as well as a preloaded mesh in order visualize the path of the probe on the patient. \\
**MENTION 3D ULTRASOUND**\\

The problem of tracking a sensor on the skin's surface was approached in \ref{3dUltrasound}. Much of the initial work on tracking the position of a probe using the orientatation and displacement was inspired by this method. In the paper however they do not deal with the deformability of the surface. This paper attempts to reconcile that problem.\\
\\
The paper also did a very simplified approach to the orientation of the sensor. We aim for a more complete solutinos. 
\subsection{Human Tracking}

Tracking human motion was approached in \ref{humanMotionTracking}. It figures out a 3D path and integrates orientation and displacement information. It does not reconcile it though with a 3D mesh of the patient. It also does not consider the deformations of the surface of a patient. With our research, we incorporate the deformations. 

\subsection{Deformable Surface Tracking}

Current work on deformable surface tracking is focused on tracking the deformations of the surface itself \cite{deformableobjecttracking,convexopt}. Additionally these works focus on surfaces that do not retain their shape after deformation. For our purposes the surfaces are elastic and thus retain their shape. This paper focuses on surfaces that deform when pressure is applied but then retain their shape afterwards. It is also focused on tracking objects on the surface rather than the surface itself.\\
\\

\subsection{Mesh Unfolding}

Being that we are tracking on a 2D surface embedded into 3D space, we thought about trying to flatten the mesh first and then track on it. We considered using a mesh flattening algorithm that used topological surgery \cite{meshunfolding}. There are other mesh flattening algorithms that exist but in the end we only used mesh flattening for a small neighborhood around where the probe currently was located. Even though the mesh flattening does not have any holes or gaps when using this algorithm, there is no way to assure that our path will not leave the boundary of the flattened mesh. Additionally, we need an algorithm to work on arbitrary meshes and the mesh flattening was only proven to work with a handful of meshes. Due to these difficulties, we decided not to flatten the entire mesh and only do local flattening when we want the path to follow the mesh, which means we care about the triangle where the path is currently as well as its neighboring triangles. 